---
# layout: page
title: Program
permalink: /program/
---

# Program

The official program will be published after the decisions of paper acceptance have been finalised (29th April 2022).

## Tentative Timeline

The workshop is a full-day meeting and will be held on 6<sup>th</sup> June 2022 in hybrid mode.

All times shown below are in EDT.

* 9.00 Welcome and introductions with ice-breaking questions 
* 9.30 Keynote 1: Isabelle Augenstein
* 10.00 Interactive paper presentation 1 
* 10.20 Interactive paper presentation 2 
* 10.40 Interactive paper presentation 3 
* 11.00 Coffee and networking break 
* 11.30 Interactive paper presentation 4 
* 12.50 Interactive paper presentation 5 
* 13.10 Interactive paper presentation 6 
* 13.30 Catered lunch 
* 14:30 Keynote 2: Zeerak Talat
* 15:00 Challenge: Come up with hard examples that trick models 
* 15:30 Group activity: Where next? Discuss experience with evaluation of models and of human evaluation
* 16:30 Coffee break 
* 17:00 Plenary: Report on group activity 
* 17:30 Closing remarks

## Interactive Paper Presentations

While all the authors of accepted papers will have the chance to record a 20 min presentation of their work that will be published on the workshop website ahead of time, live presentations will be designed to promote interaction. To give space to fresh ideas, participants will be invited to trial an innovative format for paper presentations: presenters will be given 5 minutes to describe their research questions and hypothesis, and a group discussion will start after that (10 minutes). The goal is to give time to the audience to fully appreciate the complexity of the issue targeted in the paper, and propose ideas that have not been biased from the authors' approach. At the end of the discussion, presenters will be given 5 more minutes to describe their method and results, followed by a new group discussion about the interpretation and implications of such results (10 min).

## Challenge

In the afternoon we will kick off with a small challenge: participants will be divided into groups and asked to come up with hard examples that trick existing text classifiers. To this end, we will provide an interactive model for the detection of abusive language and we will invite participants (in advance) to provide their own models and tasks for collaborative adversarial testing. The challenge will work as a warm-up session for the following group activity.

## Group Activity

This last session is meant to bring researchers together and discuss their experience with the evaluation of both models and human annotations. The goal is to collect ideas for new evaluation approaches and future work in the field and to discuss how we should organise competitions when there are multiple evaluation metrics and benchmarking datasets are dynamic. Depending on the number of participants, we will break up into small groups that reconvene after a coffee break to report resulting ideas.

## Keynote 1: Isabelle Augenstein

<div class="row" style="display:flex">
	<div class="column" style="padding:5px;flex:33%">
	    <a href="https://isabelleaugenstein.github.io/" > 
	    	<img src="http://isabelleaugenstein.github.io/images/isabelle.png" alt="Isabelle Augenstein" style="width:90%">
	    </a>
	</div>
	<div class="column" style="padding:5px;flex:66%">
	  	<p align="left"> Isabelle Augenstein is an Associate Professor at the University of Copenhagen, Department of Computer Science, where she heads the Copenhagen Natural Language Understanding research group as well as the Natural Language Processing section. Her main research interests are fact checking, low-resource learning, and explainability. Prior to starting a faculty position, she was a postdoctoral researcher at University College London, and before that a PhD student at the University of Sheffield. She currently holds a DFF Sapere Aude Research Leader fellowship on ‘Learning to Explain Attitudes on Social Media’, and is a member of the Young Royal Danish Academy of Sciences and Letters. </p>
	</div>
</div>

## Keynote 2: Zeerak Talat

Zeerak Talat is a post doctoral fellow at the Digital Democracies Institute at Simon Fraser University. Talat received a Ph.D. from the University of Sheffield. In the Ph.D., Talat worked on automated content moderation and how the practice of automating content moderation using machine learning revealed underlying the political economy of machine learning, displaying issues of access, equality, and ethical practices. Talat also founded and runs the Workshop on Online Abuse and Harms, which focuses on the technical and social developments of automated content moderation infrastructure. Talat is currently working on critical machine learning and the philosophy of machine learning, aiming to identify the specific underlying causes for why and how machine learning is a currently a marginalizing technology.